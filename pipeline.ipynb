{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.tabular.metadata.sortinghat import SortingHatFeatureMetadataEngine\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"./metadata/metadata.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "         name                                               link  \\\n0      Cancer  https://archive.ics.uci.edu/ml/datasets/Breast...   \n1       Mfeat                        https://www.openml.org/d/12   \n2     Nursery    https://archive.ics.uci.edu/ml/datasets/nursery   \n3   Audiology                         https://www.openml.org/d/7   \n4       Hayes  https://archive.ics.uci.edu/ml/datasets/Hayes-...   \n5     Supreme                       https://www.openml.org/d/728   \n6      Flares  https://archive.ics.uci.edu/ml/datasets/Solar+...   \n7       Kropt                       https://www.openml.org/d/184   \n8      Boxing                       https://www.openml.org/d/444   \n9       Flags                      https://www.openml.org/d/1012   \n10     Diggle                       https://www.openml.org/d/818   \n11     Hearts  https://archive.ics.uci.edu/ml/datasets/heart+...   \n12     Sleuth                       https://www.openml.org/d/862   \n13     Apnea2                       https://www.openml.org/d/765   \n14   Auto-MPG       https://www.kaggle.com/uciml/autompg-dataset   \n15      Churn  https://www.kaggle.com/blastchar/telco-custome...   \n16        NYC  https://www.kaggle.com/mavezdabas/nychourlytem...   \n17        BBC  https://www.kaggle.com/yufengdev/bbc-fulltext-...   \n18   Articles  https://www.kaggle.com/asad1m9a9h6mood/news-ar...   \n19   Clothing  https://www.kaggle.com/nicapotato/womens-ecomm...   \n20        IOT  https://www.kaggle.com/atulanandjha/temperatur...   \n21        Zoo        https://archive.ics.uci.edu/ml/datasets/Zoo   \n22     PBCseq                       https://www.openml.org/d/802   \n23    Pokemon         https://www.kaggle.com/rounakbanik/pokemon   \n24  President  https://www.kaggle.com/fivethirtyeight/2016-el...   \n25        MBA                       https://www.openml.org/d/190   \n26   Vineyard                       https://www.openml.org/d/500   \n27      Apnea                       https://www.openml.org/d/555   \n28   Accident         https://www.kaggle.com/kashnitsky/mlcourse   \n29   Car Fuel  https://www.kaggle.com/anderas/car-consume?sel...   \n\n                                            target  \\\n0                                   Classification   \n1                                            class   \n2                                            class   \n3                                            class   \n4                                            class   \n5                                      binaryClass   \n6                                                c   \n7                                             game   \n8                                           Winner   \n9                                      binaryClass   \n10                                     binaryClass   \n11                                          target   \n12                                     binaryClass   \n13                                     binaryClass   \n14                                          origin   \n15                                           Churn   \n16                                      Conditions   \n17                                        category   \n18                                        NewsType   \n19                                          Rating   \n20                                          out/in   \n21                                      class_type   \n22                                     binaryClass   \n23                                           type1   \n24                                           state   \n25                             grade_point_average   \n26                                            Lugs   \n27                                           Count   \n28  Accidental deaths in USA: monthly, 1973 ? 1978   \n29                                           speed   \n\n                                          truthVector  \n0                         [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2                            [1, 1, 1, 1, 1, 1, 1, 1]  \n3   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n4                             [7, 1.0, 1.0, 1.0, 1.0]  \n5                               [1, 1, 1, 1, 1, 1, 1]  \n6   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n7                                  [1, 1, 1, 1, 1, 1]  \n8                                           [7,1,1,1]  \n9   [1, 1, 0,0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n10                           [1, 0, 0, 0, 0, 0, 0, 0]  \n11                        [0,1,1,0,0,1,1,0,1,0,1,1,1]  \n12  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n13                                          [1, 1, 1]  \n14                                  [0,1,0,0,0,0,1,3]  \n15  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...  \n16                                      [2,2,0,0,0,5]  \n17                                                [3]  \n18                                          [3, 2, 3]  \n19                              [7,1,0,3,3,1,1,1,1,1]  \n20                                          [7,7,2,0]  \n21  [7.0, 1.0, 7.0, 7.0, 7.0, 1.0, 1.0, 1.0, 1.0, ...  \n22  [7, 0, 1, 0, 1, 5, 1, 1, 1, 1, 0, 5, 0, 5, 0, ...  \n23  [6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0...  \n24  [7, 7, 1, 7, 7, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n25                                              [1,1]  \n26                                            [1,0,0]  \n27                                            [1,1,1]  \n28                                                [2]  \n29  [5.0, 5.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>link</th>\n      <th>target</th>\n      <th>truthVector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cancer</td>\n      <td>https://archive.ics.uci.edu/ml/datasets/Breast...</td>\n      <td>Classification</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mfeat</td>\n      <td>https://www.openml.org/d/12</td>\n      <td>class</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nursery</td>\n      <td>https://archive.ics.uci.edu/ml/datasets/nursery</td>\n      <td>class</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Audiology</td>\n      <td>https://www.openml.org/d/7</td>\n      <td>class</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hayes</td>\n      <td>https://archive.ics.uci.edu/ml/datasets/Hayes-...</td>\n      <td>class</td>\n      <td>[7, 1.0, 1.0, 1.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Supreme</td>\n      <td>https://www.openml.org/d/728</td>\n      <td>binaryClass</td>\n      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Flares</td>\n      <td>https://archive.ics.uci.edu/ml/datasets/Solar+...</td>\n      <td>c</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Kropt</td>\n      <td>https://www.openml.org/d/184</td>\n      <td>game</td>\n      <td>[1, 1, 1, 1, 1, 1]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Boxing</td>\n      <td>https://www.openml.org/d/444</td>\n      <td>Winner</td>\n      <td>[7,1,1,1]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Flags</td>\n      <td>https://www.openml.org/d/1012</td>\n      <td>binaryClass</td>\n      <td>[1, 1, 0,0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Diggle</td>\n      <td>https://www.openml.org/d/818</td>\n      <td>binaryClass</td>\n      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Hearts</td>\n      <td>https://archive.ics.uci.edu/ml/datasets/heart+...</td>\n      <td>target</td>\n      <td>[0,1,1,0,0,1,1,0,1,0,1,1,1]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Sleuth</td>\n      <td>https://www.openml.org/d/862</td>\n      <td>binaryClass</td>\n      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Apnea2</td>\n      <td>https://www.openml.org/d/765</td>\n      <td>binaryClass</td>\n      <td>[1, 1, 1]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Auto-MPG</td>\n      <td>https://www.kaggle.com/uciml/autompg-dataset</td>\n      <td>origin</td>\n      <td>[0,1,0,0,0,0,1,3]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Churn</td>\n      <td>https://www.kaggle.com/blastchar/telco-custome...</td>\n      <td>Churn</td>\n      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NYC</td>\n      <td>https://www.kaggle.com/mavezdabas/nychourlytem...</td>\n      <td>Conditions</td>\n      <td>[2,2,0,0,0,5]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>BBC</td>\n      <td>https://www.kaggle.com/yufengdev/bbc-fulltext-...</td>\n      <td>category</td>\n      <td>[3]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Articles</td>\n      <td>https://www.kaggle.com/asad1m9a9h6mood/news-ar...</td>\n      <td>NewsType</td>\n      <td>[3, 2, 3]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Clothing</td>\n      <td>https://www.kaggle.com/nicapotato/womens-ecomm...</td>\n      <td>Rating</td>\n      <td>[7,1,0,3,3,1,1,1,1,1]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>IOT</td>\n      <td>https://www.kaggle.com/atulanandjha/temperatur...</td>\n      <td>out/in</td>\n      <td>[7,7,2,0]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Zoo</td>\n      <td>https://archive.ics.uci.edu/ml/datasets/Zoo</td>\n      <td>class_type</td>\n      <td>[7.0, 1.0, 7.0, 7.0, 7.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>PBCseq</td>\n      <td>https://www.openml.org/d/802</td>\n      <td>binaryClass</td>\n      <td>[7, 0, 1, 0, 1, 5, 1, 1, 1, 1, 0, 5, 0, 5, 0, ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Pokemon</td>\n      <td>https://www.kaggle.com/rounakbanik/pokemon</td>\n      <td>type1</td>\n      <td>[6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>President</td>\n      <td>https://www.kaggle.com/fivethirtyeight/2016-el...</td>\n      <td>state</td>\n      <td>[7, 7, 1, 7, 7, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>MBA</td>\n      <td>https://www.openml.org/d/190</td>\n      <td>grade_point_average</td>\n      <td>[1,1]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Vineyard</td>\n      <td>https://www.openml.org/d/500</td>\n      <td>Lugs</td>\n      <td>[1,0,0]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Apnea</td>\n      <td>https://www.openml.org/d/555</td>\n      <td>Count</td>\n      <td>[1,1,1]</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Accident</td>\n      <td>https://www.kaggle.com/kashnitsky/mlcourse</td>\n      <td>Accidental deaths in USA: monthly, 1973 ? 1978</td>\n      <td>[2]</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Car Fuel</td>\n      <td>https://www.kaggle.com/anderas/car-consume?sel...</td>\n      <td>speed</td>\n      <td>[5.0, 5.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "classif_data = {\n",
    "    \"NU\" : [\"Cancer\", \"MFeat\"],\n",
    "    \"CA\" : [\"Nursery\", \"Audiology\", \"Hayes\", \"Supreme\", \"Flares\", \"Kropt\", \"Boxing\"],\n",
    "    \"CA+NG\" : [\"Apnea2\"],\n",
    "    \"NU+CA\" : [\"Flags\", \"Diggle\", \"Hearts\", \"Sleuth\"],\n",
    "    \"NU+CA+ST\" : [\"Auto-MPG\"],\n",
    "    \"NU+CA+ST+NG\" : [\"Clothing\"],\n",
    "    \"NU+DT+NG\" : [\"IOT\"],\n",
    "    \"NU+DT+EN\" : [\"NYC\"],\n",
    "    \"ST\" : [\"BBC\"],\n",
    "    \"DT+ST\" : [\"Articles\"],\n",
    "    \"NG+CA\" : [\"Zoo\"],\n",
    "    \"NU+CA+EN\" : [\"Churn\"],\n",
    "    \"NU+CA+EN+NG\" : [\"PBCseq\"],\n",
    "    \"NU+CA+LST+NG+CS\" : [\"Pokemon\"],\n",
    "    \"NU+CA+DT+URL+NG+CS\" : [\"President\"]\n",
    "}\n",
    "\n",
    "reg_data = {\n",
    "    \"CA\" : [\"MBA\"],\n",
    "    \"NU+CA\" : [\"Vineyard\", \"Apnea\"],\n",
    "    \"DT\" : [\"Accident\"],\n",
    "    \"NU+CA+EN+NG\" : [\"Car Fuel\"]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211120_063509/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211120_063509/\"\n",
      "AutoGluon Version:  0.3.1b20211115\n",
      "Train Data Rows:    10368\n",
      "Train Data Columns: 8\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['very_recom', 'spec_prior', 'priority', 'not_recom', 'recommend']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9998070987654321\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1311.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.39 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', []) : 8 | ['parents', 'has_nurs', 'form', 'children', 'housing', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['parents', 'has_nurs', 'form', 'children', 'housing', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['finance']\n",
      "\t0.6s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install fastai==2.*`. If you are using Mac OSX, please use this torch version to avoid compatibility issues: `pip install torch==1.6.0`.\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.9835\t = Validation score   (accuracy)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.9847\t = Validation score   (accuracy)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed.A quick tip is to install via `pip install catboost`.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.9746\t = Validation score   (accuracy)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.9756\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t12.86s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install fastai==2.*`. If you are using Mac OSX, please use this torch version to avoid compatibility issues: `pip install torch==1.6.0`.\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed.A quick tip is to install via `pip install catboost`.\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\t0.9998\t = Validation score   (accuracy)\n",
      "\t5.42s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 29.53s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211120_063509/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           parents   has_nurs        form children     housing     finance  \\\n",
      "4865   pretentious     proper  incomplete        3  convenient  convenient   \n",
      "6255   pretentious   improper    complete     more    critical      inconv   \n",
      "10567   great_pret   improper    complete     more    critical  convenient   \n",
      "7863   pretentious  very_crit    complete        2   less_conv      inconv   \n",
      "11923   great_pret   critical      foster        1    critical  convenient   \n",
      "\n",
      "              social       health  \n",
      "4865   slightly_prob    not_recom  \n",
      "6255         nonprob  recommended  \n",
      "10567        nonprob     priority  \n",
      "7863     problematic  recommended  \n",
      "11923    problematic     priority  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.9996141975308642\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9996141975308642,\n",
      "    \"balanced_accuracy\": 0.9997119815668203,\n",
      "    \"mcc\": 0.9994372287518047\n",
      "}\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211120_063539/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211120_063539/\"\n",
      "AutoGluon Version:  0.3.1b20211115\n",
      "Train Data Rows:    10368\n",
      "Train Data Columns: 8\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t5 unique label values:  ['very_recom', 'spec_prior', 'priority', 'not_recom', 'recommend']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 5 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9998070987654321\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1402.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.39 MB (0.4% of available memory)\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9\n",
      "9 9 9 9\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"parents\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"has_nurs\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"form\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"children\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"housing\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"finance\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"social\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Actual dtype differs from dtype in FeatureMetadata for feature \"health\". Actual dtype: object | Expected dtype: category\n",
      "\t\t\tWARNING: Forcefully converting features to expected dtypes. Please manually align the input data with the expected dtypes if issues occur.\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['parents', 'has_nurs', 'form', 'children', 'housing', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['parents', 'has_nurs', 'form', 'children', 'housing', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['finance']\n",
      "\t0.6s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install fastai==2.*`. If you are using Mac OSX, please use this torch version to avoid compatibility issues: `pip install torch==1.6.0`.\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.9835\t = Validation score   (accuracy)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.9847\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed.A quick tip is to install via `pip install catboost`.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.9746\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.9756\t = Validation score   (accuracy)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t11.24s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install fastai==2.*`. If you are using Mac OSX, please use this torch version to avoid compatibility issues: `pip install torch==1.6.0`.\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed.A quick tip is to install via `pip install catboost`.\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\t0.9998\t = Validation score   (accuracy)\n",
      "\t5.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install lightgbm`.\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 26.82s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211120_063539/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           parents   has_nurs        form children     housing     finance  \\\n",
      "4865   pretentious     proper  incomplete        3  convenient  convenient   \n",
      "6255   pretentious   improper    complete     more    critical      inconv   \n",
      "10567   great_pret   improper    complete     more    critical  convenient   \n",
      "7863   pretentious  very_crit    complete        2   less_conv      inconv   \n",
      "11923   great_pret   critical      foster        1    critical  convenient   \n",
      "\n",
      "              social       health  \n",
      "4865   slightly_prob    not_recom  \n",
      "6255         nonprob  recommended  \n",
      "10567        nonprob     priority  \n",
      "7863     problematic  recommended  \n",
      "11923    problematic     priority  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.9996141975308642\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9996141975308642,\n",
      "    \"balanced_accuracy\": 0.9997119815668203,\n",
      "    \"mcc\": 0.9994372287518047\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/jj/st19g0h11dj2btjtztczv4bc0000gn/T/ipykernel_34400/1070444951.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mperf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclassif_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'CA'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetadata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/jj/st19g0h11dj2btjtztczv4bc0000gn/T/ipykernel_34400/1070444951.py\u001B[0m in \u001B[0;36mpipeline\u001B[0;34m(data_dict, category, metadata)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0;31m#perf0 = agl_downstream(df, train_data, test_data, label, predictor_type=0, truth_vec=truth_vec)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mperf0\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mperf1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magl_downstream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictor_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mperf2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magl_downstream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictor_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperf0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperf1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperf2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/jj/st19g0h11dj2btjtztczv4bc0000gn/T/ipykernel_34400/1070444951.py\u001B[0m in \u001B[0;36mpipeline\u001B[0;34m(data_dict, category, metadata)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0;31m#perf0 = agl_downstream(df, train_data, test_data, label, predictor_type=0, truth_vec=truth_vec)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mperf0\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mperf1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magl_downstream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictor_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mperf2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magl_downstream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictor_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperf0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperf1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperf2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    745\u001B[0m                 \u001B[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    746\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpydev_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mSTATE_SUSPEND\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 747\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    748\u001B[0m                     \u001B[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    749\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrace_dispatch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[0;31m# IFDEF CYTHON\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "sh_engine = SortingHatFeatureMetadataEngine()\n",
    "\n",
    "def pipeline(data_dict, category, metadata):\n",
    "    res = []\n",
    "    for name in data_dict[category]:\n",
    "        file_name = name.lower().replace(' ', '_') + '.csv'\n",
    "        df = pd.read_csv('./data/' + file_name)\n",
    "        truth_vec = metadata.loc[metadata.name == name].iloc[0,3]\n",
    "        label = list(df.columns)[-1]  # specifies which column do we want to predict\n",
    "        data = TabularDataset(df)\n",
    "        train_data, test_data = train_test_split(data, test_size=0.2, random_state=25)\n",
    "        #perf0 = agl_downstream(df, train_data, test_data, label, predictor_type=0, truth_vec=truth_vec)\n",
    "        perf0=None\n",
    "        perf1 = agl_downstream(df, train_data, test_data, label, predictor_type=1)\n",
    "        perf2 = agl_downstream(df, train_data, test_data, label, predictor_type=2)\n",
    "        res.append([name, perf0, perf1, perf2])\n",
    "    return pd.DataFrame(res, columns=['Name', 'Truth', 'AGL', 'AGL+SH'])\n",
    "\n",
    "'''\n",
    "predictor_type: {0, 1, 2}\n",
    "0 represents using true feature types\n",
    "1 represents using AutoGluon auto-inferred feature types\n",
    "2 represents using SortingHat inferred feature types\n",
    "'''\n",
    "def agl_downstream(df, train_data, test_data, label, predictor_type=1, truth_vec=None):\n",
    "    # exclude other tree based models\n",
    "    excluded = ['CAT', 'GBM', 'XT', 'custom']\n",
    "    if predictor_type == 0:\n",
    "        true_feature_metadata = sh_engine.to_feature_metadata(df, truth_vec)\n",
    "        predictor = TabularPredictor(label=label, eval_metric= \"accuracy\").fit(train_data, feature_metadata=true_feature_metadata, presets='best_quality', excluded_model_types=excluded)\n",
    "    elif predictor_type == 2:\n",
    "        predictor = TabularPredictor(label=label, eval_metric= \"accuracy\").fit(train_data, use_metadata_engine=True, presets='best_quality', excluded_model_types=excluded)\n",
    "    else:\n",
    "        predictor = TabularPredictor(label=label, eval_metric= \"accuracy\").fit(train_data, presets='best_quality', excluded_model_types=excluded)\n",
    "\n",
    "    # results = predictor.fit_summary(show_plot=True)\n",
    "    # Inference time:\n",
    "    y_test = test_data[label]\n",
    "    test_data = test_data.drop(labels=[label], axis=1)  # delete labels from test data since we wouldn't have them in practice\n",
    "    print(test_data.head())\n",
    "    y_pred = predictor.predict(test_data)\n",
    "    perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n",
    "    predictor.leaderboard()\n",
    "    return perf\n",
    "\n",
    "pipeline(classif_data, 'CA', metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}